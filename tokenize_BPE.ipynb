{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import tiktoken\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "</w>: [0, 94460]\n",
      "N: [1, 1110]\n",
      "e: [2, 56334]\n",
      "t: [3, 37991]\n",
      "w: [4, 3485]\n",
      "o: [5, 28926]\n",
      "r: [6, 27428]\n",
      "k: [7, 1151]\n",
      "W: [8, 317]\n",
      "i: [9, 28690]\n",
      "voca:  83\n"
     ]
    }
   ],
   "source": [
    "raw_text = \"\"\n",
    "\n",
    "with open(\"rfc.txt\", \"r\") as file:\n",
    "    raw_text = file.read()\n",
    "\n",
    "#print(len(raw_text))\n",
    "#raw_text = raw_text[:100]\n",
    "\n",
    "# split into word\n",
    "raw_words = re.split(r'\\s+|[.,!?:;\\'\"()\\-]', raw_text)\n",
    "\n",
    "words = []\n",
    "\n",
    "voca_index = 0\n",
    "voca_pos = []\n",
    "voca = {\"</w>\": [voca_index, 0]}\n",
    "voca_pos.append(\"</w>\")\n",
    "voca_index += 1\n",
    "\n",
    "for w in raw_words:\n",
    "    if w.strip():\n",
    "        for c in w:\n",
    "            if c in voca:\n",
    "                voca[c][1] += 1\n",
    "            else:\n",
    "                voca[c] = [voca_index, 1]\n",
    "                voca_pos.append(c)\n",
    "                voca_index += 1\n",
    "        voca[\"</w>\"][1] += 1\n",
    "\n",
    "        words.append(w)\n",
    "\n",
    "#print(len(words))\n",
    "#print(words[:10])\n",
    "\n",
    "for i, (char, count) in enumerate(voca.items()):\n",
    "    if i >= 10:\n",
    "        break\n",
    "    print(f\"{char}: {count}\")\n",
    "\n",
    "print(\"voca: \", len(voca))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['N', 'e', 't', 'w', 'o', 'r', 'k', '</w>'], ['W', 'o', 'r', 'k', 'i', 'n', 'g', '</w>'], ['G', 'r', 'o', 'u', 'p', '</w>'], ['J', '</w>'], ['R', 'o', 's', 'e', 'n', 'b', 'e', 'r', 'g', '</w>'], ['R', 'e', 'q', 'u', 'e', 's', 't', '</w>'], ['f', 'o', 'r', '</w>'], ['C', 'o', 'm', 'm', 'e', 'n', 't', 's', '</w>'], ['3', '2', '6', '1', '</w>'], ['d', 'y', 'n', 'a', 'm', 'i', 'c', 's', 'o', 'f', 't', '</w>']]\n",
      "</w>: [0, 94460]\n",
      "N: [1, 1110]\n",
      "e: [2, 56334]\n",
      "t: [3, 37991]\n",
      "w: [4, 3485]\n",
      "o: [5, 28926]\n",
      "r: [6, 27428]\n",
      "k: [7, 1151]\n",
      "W: [8, 317]\n",
      "i: [9, 28690]\n"
     ]
    }
   ],
   "source": [
    "words = [list(w) for w in words]\n",
    "for l_w in words:\n",
    "    l_w.append(\"</w>\")\n",
    "\n",
    "#print(\"words\", words[:10])\n",
    "\n",
    "encoded = []\n",
    "for w in words:\n",
    "    encoded.append([voca[c][0] for c in w])\n",
    "\n",
    "print(words[:10])\n",
    "\n",
    "#print 10 item in voca\n",
    "for i, (char, count) in enumerate(voca.items()):\n",
    "    if i >= 10:\n",
    "        break\n",
    "    print(f\"{char}: {count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No more pair to merge\n",
      "3535\n",
      "['Ber', 'School', 'Schooler</w>', 'abs</w>', 'Copyright</w>', 'kind</w>', 'ual</w>', 'PA', 'Soci', 'Society</w>']\n",
      "[[1, 195, 824], [3117, 1403], [12, 393, 205], [1594], [357], [351], [161], [1072, 1536], [366], [3658]]\n",
      "word [['N', 'e', 't', 'w', 'o', 'r', 'k', '</w>'], ['W', 'o', 'r', 'k', 'i', 'n', 'g', '</w>'], ['G', 'r', 'o', 'u', 'p', '</w>'], ['J', '</w>'], ['R', 'o', 's', 'e', 'n', 'b', 'e', 'r', 'g', '</w>'], ['R', 'e', 'q', 'u', 'e', 's', 't', '</w>'], ['f', 'o', 'r', '</w>'], ['C', 'o', 'm', 'm', 'e', 'n', 't', 's', '</w>'], ['3', '2', '6', '1', '</w>'], ['d', 'y', 'n', 'a', 'm', 'i', 'c', 's', 'o', 'f', 't', '</w>']]\n"
     ]
    }
   ],
   "source": [
    "max_voca_size = 10000\n",
    "while len(voca) < max_voca_size:\n",
    "    pair_count = {}\n",
    "    max_pair = 0\n",
    "    firstPart, secondPart = -1, -1\n",
    "\n",
    "    # Count the frequency of each pair of characters\n",
    "    for w in encoded:\n",
    "        for i in range(len(w) - 1):\n",
    "            pair = (w[i], w[i+1])\n",
    "            if pair in pair_count:\n",
    "                pair_count[pair] += 1\n",
    "            else:\n",
    "                pair_count[pair] = 1\n",
    "\n",
    "            if pair_count[pair] > max_pair:\n",
    "                max_pair = pair_count[pair]\n",
    "                firstPart = w[i]\n",
    "                secondPart = w[i+1]\n",
    "    \n",
    "    # print(max_pair)\n",
    "    #print(firstPart, secondPart)\n",
    "    if firstPart == -1 or secondPart == -1 or max_pair < 5:\n",
    "        print(\"No more pair to merge\")\n",
    "        break\n",
    "\n",
    "    # Merge the most frequent pair\n",
    "    newpair = voca_index\n",
    "    voca_index += 1\n",
    "    merged = voca_pos[firstPart] + voca_pos[secondPart]\n",
    "    voca_pos.append(merged)\n",
    "\n",
    "    # Update the encoded words\n",
    "    voca[merged] = [voca_index, max_pair]\n",
    "    voca[voca_pos[firstPart]][1] -= max_pair\n",
    "    voca[voca_pos[secondPart]][1] -= max_pair\n",
    "    if voca[voca_pos[firstPart]][1] == 0:\n",
    "        del voca[voca_pos[firstPart]]\n",
    "    if voca[voca_pos[secondPart]][1] == 0:\n",
    "        del voca[voca_pos[secondPart]]\n",
    "\n",
    "    #print(len(voca))\n",
    "    #print(voca[merged])\n",
    "    #print(merged)\n",
    "\n",
    "    #replace the pair in the encoded words\n",
    "    isMerged = False\n",
    "    for w in encoded:\n",
    "        i = 0\n",
    "        while i < len(w) - 1:\n",
    "            if w[i] == firstPart and w[i+1] == secondPart:\n",
    "                w[i] = newpair\n",
    "                w.pop(i+1)\n",
    "                isMerged = True\n",
    "            i += 1\n",
    "    #print(\"merge status\", isMerged)\n",
    "    #print(len(encoded))        \n",
    "    \n",
    "print(len(voca))\n",
    "\n",
    "# print 10 last item in voca_pos\n",
    "print(voca_pos[-10:])\n",
    "\n",
    "print(encoded[:10])\n",
    "\n",
    "print(\"word\", words[:10])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2735, 3]\n",
      "[84, 65]\n"
     ]
    }
   ],
   "source": [
    "print(voca[\"knowledg\"])\n",
    "print(voca[\"e</w>\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['N', 'et', 'work</w>'], ['Wor', 'king</w>'], ['G', 'rou', 'p</w>'], ['J</w>'], ['Rosenberg</w>'], ['Request</w>'], ['for</w>'], ['Com', 'ments</w>'], ['3261</w>'], ['dynamicsoft</w>']]\n"
     ]
    }
   ],
   "source": [
    "decode = []\n",
    "\n",
    "for w in encoded:\n",
    "    decode.append([voca_pos[c] for c in w])\n",
    "\n",
    "print(decode[:10])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
